{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "65814af9",
   "metadata": {},
   "source": [
    "# BanVic Data Pipeline: From Raw CSV to a Full Data Warehouse\n",
    "\n",
    "This notebook executes the full ELT (Extract, Load, Transform) process for the BanVic project in DuckDB. It handles:\n",
    "1.  **Extract & Load:** Reading source CSVs into a `raw` layer (`raw_banvic.db`).\n",
    "2.  **Transform (Staging):** Cleaning and standardizing the raw data into a `staging` layer (`stg_banvic.db`).\n",
    "3.  **Verify:** Running data quality checks on the `staging` layer.\n",
    "4.  **Transform (Data Warehouse):** Modeling the clean data into a final Star Schema in the `dw_banvic.db`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f318321",
   "metadata": {},
   "source": [
    "## Step 1: Create and Populate the Raw Layer (`raw_banvic.db`)\n",
    "\n",
    "The first step is to load the original, untouched CSV files into our `raw` database. This serves as the single source of truth for our pipeline. Each CSV file is loaded into a corresponding table within the `raw` schema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "47f0cacb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Loading raw data into DuckDB ---\n",
      "Table 'raw.agencies' created successfully.\n",
      "Table 'raw.bank_accounts' created successfully.\n",
      "Table 'raw.clients' created successfully.\n",
      "Table 'raw.credit_proposal' created successfully.\n",
      "Table 'raw.employee' created successfully.\n",
      "Table 'raw.employee_agency' created successfully.\n",
      "Table 'raw.transactions' created successfully.\n",
      "\n",
      "--- Raw data loading complete. ---\n"
     ]
    }
   ],
   "source": [
    "import duckdb\n",
    "import os\n",
    "\n",
    "# --- Configuration ---\n",
    "# Define the path for the database file\n",
    "db_file = '../database/raw_banvic.db'\n",
    "# Define the path to the raw data directory\n",
    "data_dir = '../data'\n",
    "\n",
    "# --- Execution ---\n",
    "# Connect to the database file (it will be created if it doesn't exist)\n",
    "con = duckdb.connect(db_file)\n",
    "\n",
    "# Create the schema for the raw data\n",
    "con.execute(\"CREATE SCHEMA IF NOT EXISTS raw;\")\n",
    "\n",
    "csv_files = [f for f in os.listdir(data_dir) if f.endswith('.csv')]\n",
    "\n",
    "# Loop to load each CSV into a table in the 'raw' schema\n",
    "print(\"--- Loading raw data into DuckDB ---\")\n",
    "for file in csv_files:\n",
    "    table_name = file.replace('.csv', '')\n",
    "    file_path = os.path.join(data_dir, file).replace('\\\\', '/')\n",
    "    \n",
    "    # This query creates a table in the 'raw' schema with the same name as the file\n",
    "    con.execute(f\"\"\"\n",
    "        CREATE OR REPLACE TABLE raw.{table_name} AS \n",
    "        SELECT * FROM read_csv_auto('{file_path}');\n",
    "    \"\"\")\n",
    "    print(f\"Table 'raw.{table_name}' created successfully.\")\n",
    "\n",
    "con.close()\n",
    "print(\"\\n--- Raw data loading complete. ---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25984016",
   "metadata": {},
   "source": [
    "## Step 2: Create and Populate the Staging Layer (`stg_banvic.db`)\n",
    "\n",
    "This is the core transformation step. The following script connects to our target staging database (`stg_banvic.db`) and **attaches** the source raw database (`raw_banvic.db`).\n",
    "\n",
    "It then executes a series of SQL queries to transform the raw data by:\n",
    "- Renaming columns to an English standard.\n",
    "- Casting data types correctly (e.g., to `VARCHAR`, `DATE`).\n",
    "- Standardizing text fields (e.g., `zip_code`).\n",
    "- Parsing new information from existing columns (e.g., `parsed_state`).\n",
    "- Filtering out known data integrity issues (e.g., the orphan account)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ca3c2a63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully connected to '../database/stg_banvic.db'\n",
      "Successfully attached '../database/raw_banvic.db' as 'raw_db'\n",
      "Schema 'stg' is ready.\n",
      "\n",
      "--- Running Staging Transformations ---\n",
      "Table 'stg.agencies' created successfully.\n",
      "Table 'stg.clients' created successfully.\n",
      "Table 'stg.bank_accounts' created successfully.\n",
      "Table 'stg.employee' created successfully.\n",
      "Table 'stg.employee_agency' created successfully.\n",
      "Table 'stg.transactions' created successfully.\n",
      "Table 'stg.credit_proposal' created successfully.\n",
      "\n",
      "--- Staging layer created successfully. ---\n",
      "\n",
      "Database connection closed.\n"
     ]
    }
   ],
   "source": [
    "import duckdb\n",
    "import os\n",
    "\n",
    "# --- Configuration ---\n",
    "# Path to the STAGING database file (where we will write data)\n",
    "stg_db_file = '../database/stg_banvic.db'\n",
    "# Path to the RAW database file (where we will read data from)\n",
    "raw_db_file = '../database/raw_banvic.db'\n",
    "\n",
    "# --- SQL Queries for Staging Layer ---\n",
    "\n",
    "# A list to hold all transformation queries\n",
    "staging_queries = [\n",
    "    {\n",
    "        \"table_name\": \"agencies\",\n",
    "        \"sql\": \"\"\"\n",
    "            CREATE OR REPLACE TABLE stg.agencies AS\n",
    "            SELECT\n",
    "                cod_agencia::VARCHAR AS agency_id,\n",
    "                CAST(data_abertura AS DATE) AS opening_date,\n",
    "                nome AS agency_name,\n",
    "                endereco AS address,\n",
    "                cidade AS city,\n",
    "                uf AS state,\n",
    "                tipo_agencia AS agency_type\n",
    "            FROM\n",
    "                raw_db.raw.agencies; -- Read from the attached raw_db\n",
    "        \"\"\"\n",
    "    },\n",
    "    {\n",
    "        \"table_name\": \"clients\",\n",
    "        \"sql\": \"\"\"\n",
    "            CREATE OR REPLACE TABLE stg.clients AS\n",
    "            SELECT\n",
    "                cod_cliente::VARCHAR AS client_id,\n",
    "                CAST(data_inclusao AS DATE) AS inclusion_date,\n",
    "                CAST(data_nascimento AS DATE) AS birth_date,\n",
    "                primeiro_nome AS first_name,\n",
    "                ultimo_nome AS last_name,\n",
    "                email,\n",
    "                tipo_cliente AS client_type,\n",
    "                cpfcnpj::VARCHAR AS cpf_cnpj,\n",
    "                endereco AS full_address,\n",
    "                regexp_replace(cep, '[^0-9]', '', 'g')::VARCHAR AS zip_code,\n",
    "                regexp_extract(endereco, '/ ([A-Z]{2})$') AS parsed_state\n",
    "            FROM\n",
    "                raw_db.raw.clients; -- Read from the attached raw_db\n",
    "        \"\"\"\n",
    "    },\n",
    "    {\n",
    "        \"table_name\": \"bank_accounts\",\n",
    "        \"sql\": \"\"\"\n",
    "            CREATE OR REPLACE TABLE stg.bank_accounts AS\n",
    "            SELECT\n",
    "                CAST(b.num_conta AS VARCHAR) AS account_id,\n",
    "                CAST(b.cod_cliente AS VARCHAR) AS client_id,\n",
    "                CAST(b.cod_agencia AS VARCHAR) AS agency_id,\n",
    "                CAST(b.cod_colaborador AS VARCHAR) AS employee_id,\n",
    "                CAST(b.data_abertura AS DATE) AS opening_date,\n",
    "                CAST(b.data_ultimo_lancamento AS DATE) AS last_transaction_date,\n",
    "                b.tipo_conta AS account_type,\n",
    "                b.saldo_total AS total_balance,\n",
    "                b.saldo_disponivel AS available_balance\n",
    "            FROM\n",
    "                raw_db.raw.bank_accounts AS b -- Read from the attached raw_db\n",
    "            INNER JOIN\n",
    "                raw_db.raw.clients AS c ON b.cod_cliente = c.cod_cliente;\n",
    "        \"\"\"\n",
    "    },\n",
    "    {\n",
    "        \"table_name\": \"employee\",\n",
    "        \"sql\": \"\"\"\n",
    "            CREATE OR REPLACE TABLE stg.employee AS\n",
    "            SELECT\n",
    "                cod_colaborador::VARCHAR AS employee_id,\n",
    "                CAST(data_nascimento AS DATE) AS birth_date,\n",
    "                primeiro_nome AS first_name,\n",
    "                ultimo_nome AS last_name,\n",
    "                email,\n",
    "                cpf::VARCHAR AS cpf,\n",
    "                endereco AS address,\n",
    "                regexp_replace(cep, '[^0-9]', '', 'g')::VARCHAR AS zip_code\n",
    "            FROM\n",
    "                raw_db.raw.employee; -- Read from the attached raw_db\n",
    "        \"\"\"\n",
    "    },\n",
    "    {\n",
    "        \"table_name\": \"employee_agency\",\n",
    "        \"sql\": \"\"\"\n",
    "            CREATE OR REPLACE TABLE stg.employee_agency AS\n",
    "            SELECT\n",
    "                cod_colaborador::VARCHAR AS employee_id,\n",
    "                cod_agencia::VARCHAR AS agency_id\n",
    "            FROM\n",
    "                raw_db.raw.employee_agency; -- Read from the attached raw_db\n",
    "        \"\"\"\n",
    "    },\n",
    "    {\n",
    "        \"table_name\": \"transactions\",\n",
    "        \"sql\": \"\"\"\n",
    "            CREATE OR REPLACE TABLE stg.transactions AS\n",
    "            SELECT\n",
    "                cod_transacao::VARCHAR AS transaction_id,\n",
    "                num_conta::VARCHAR AS account_id,\n",
    "                CAST(data_transacao AS TIMESTAMP WITH TIME ZONE) AS transaction_date,\n",
    "                nome_transacao AS transaction_name,\n",
    "                valor_transacao AS transaction_amount\n",
    "            FROM\n",
    "                raw_db.raw.transactions; -- Read from the attached raw_db\n",
    "        \"\"\"\n",
    "    },\n",
    "    {\n",
    "        \"table_name\": \"credit_proposal\",\n",
    "        \"sql\": \"\"\"\n",
    "            CREATE OR REPLACE TABLE stg.credit_proposal AS\n",
    "            SELECT\n",
    "                cod_proposta::VARCHAR AS proposal_id,\n",
    "                cod_cliente::VARCHAR AS client_id,\n",
    "                cod_colaborador::VARCHAR AS employee_id,\n",
    "                CAST(data_entrada_proposta AS DATE) AS proposal_date,\n",
    "                taxa_juros_mensal AS monthly_interest_rate,\n",
    "                valor_proposta AS proposal_amount,\n",
    "                valor_financiamento AS financing_amount,\n",
    "                valor_entrada AS down_payment_amount,\n",
    "                valor_prestacao AS installment_amount,\n",
    "                quantidade_parcelas AS number_of_installments,\n",
    "                carencia AS grace_period,\n",
    "                status_proposta AS proposal_status\n",
    "            FROM\n",
    "                raw_db.raw.credit_proposal; -- Read from the attached raw_db\n",
    "        \"\"\"\n",
    "    }\n",
    "]\n",
    "\n",
    "# --- Execution ---\n",
    "con = None\n",
    "try:\n",
    "    # Connect to the STAGING database file (our target)\n",
    "    con = duckdb.connect(stg_db_file)\n",
    "    print(f\"Successfully connected to '{stg_db_file}'\")\n",
    "\n",
    "    # Attach the RAW database file, giving it an alias 'raw_db'\n",
    "    con.execute(f\"ATTACH '{raw_db_file.replace('\\\\', '/')}' AS raw_db (READ_ONLY);\")\n",
    "    print(f\"Successfully attached '{raw_db_file}' as 'raw_db'\")\n",
    "\n",
    "    # Create the staging schema if it doesn't exist\n",
    "    con.execute(\"CREATE SCHEMA IF NOT EXISTS stg;\")\n",
    "    print(\"Schema 'stg' is ready.\")\n",
    "\n",
    "    # Loop to execute each transformation query\n",
    "    print(\"\\n--- Running Staging Transformations ---\")\n",
    "    for item in staging_queries:\n",
    "        table_name = item[\"table_name\"]\n",
    "        sql_query = item[\"sql\"]\n",
    "        \n",
    "        con.execute(sql_query)\n",
    "        print(f\"Table 'stg.{table_name}' created successfully.\")\n",
    "\n",
    "    print(\"\\n--- Staging layer created successfully. ---\")\n",
    "\n",
    "finally:\n",
    "    # Ensure the connection is closed\n",
    "    if con:\n",
    "        con.close()\n",
    "        print(\"\\nDatabase connection closed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6725cb6",
   "metadata": {},
   "source": [
    "## Specific Verifications\n",
    "\n",
    "Here we run specific tests to ensure the cleaning steps were successful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e27441a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:27: SyntaxWarning: invalid escape sequence '\\D'\n",
      "<>:27: SyntaxWarning: invalid escape sequence '\\D'\n",
      "C:\\Users\\Rodolfo\\AppData\\Local\\Temp\\ipykernel_14308\\936216409.py:27: SyntaxWarning: invalid escape sequence '\\D'\n",
      "  SELECT zip_code FROM stg.clients WHERE regexp_matches(zip_code, '\\D')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully connected to '../database/stg_banvic.db' for verification.\n",
      "\n",
      "--- Running Specific Verification Tests ---\n",
      "✅ PASSED: 'stg.bank_accounts' has 998 rows, orphan account correctly filtered.\n",
      "✅ PASSED: 'zip_code' column in 'stg.clients' is successfully standardized (contains only digits).\n",
      "\n",
      "[Value Counts for 'parsed_state' in stg.clients]\n",
      "   parsed_state  count\n",
      "0          / AM     53\n",
      "1          / ES     49\n",
      "2          / SP     48\n",
      "3          / MS     47\n",
      "4          / MA     44\n",
      "5          / CE     43\n",
      "6          / RR     41\n",
      "7          / AL     40\n",
      "8          / MG     40\n",
      "9          / AC     38\n",
      "10         / PB     37\n",
      "11         / TO     37\n",
      "12         / SC     37\n",
      "13         / AP     35\n",
      "14         / RS     35\n",
      "15         / RN     34\n",
      "16         / BA     34\n",
      "17         / GO     34\n",
      "18         / PR     33\n",
      "19         / DF     33\n",
      "20         / PA     33\n",
      "21         / RJ     32\n",
      "22         / PI     31\n",
      "23         / SE     29\n",
      "24         / PE     28\n",
      "25         / MT     28\n",
      "26         / RO     25\n",
      "\n",
      "Database connection for verification closed.\n"
     ]
    }
   ],
   "source": [
    "import duckdb\n",
    "import pandas as pd\n",
    "\n",
    "# Define the path to the database we want to test\n",
    "stg_db_file = '../database/stg_banvic.db'\n",
    "\n",
    "con = None\n",
    "try:\n",
    "    # Step 1: Open a new connection for this cell's scope\n",
    "    # read_only=True is a good practice for test scripts\n",
    "    con = duckdb.connect(stg_db_file, read_only=True)\n",
    "    print(f\"Successfully connected to '{stg_db_file}' for verification.\")\n",
    "    \n",
    "    print(\"\\n--- Running Specific Verification Tests ---\")\n",
    "    \n",
    "    # Test 1: Verify orphan account was filtered from 'bank_accounts'\n",
    "    # The raw table had 999 rows. The staging table should have 998.\n",
    "    bank_accounts_count = con.execute(\"SELECT COUNT(*) FROM stg.bank_accounts;\").fetchone()[0]\n",
    "    if bank_accounts_count == 998:\n",
    "        print(f\"✅ PASSED: 'stg.bank_accounts' has {bank_accounts_count} rows, orphan account correctly filtered.\")\n",
    "    else:\n",
    "        print(f\"❌ FAILED: 'stg.bank_accounts' has {bank_accounts_count} rows, expected 998.\")\n",
    "\n",
    "    # Test 2: Verify zip_code standardization in 'clients'\n",
    "    # This query should find 0 rows with non-digit characters in zip_code.\n",
    "    non_digit_zips_clients = con.execute(\"\"\"\n",
    "        SELECT zip_code FROM stg.clients WHERE regexp_matches(zip_code, '\\D')\n",
    "    \"\"\").fetchall()\n",
    "    if len(non_digit_zips_clients) == 0:\n",
    "        print(\"✅ PASSED: 'zip_code' column in 'stg.clients' is successfully standardized (contains only digits).\")\n",
    "    else:\n",
    "        print(\"❌ FAILED: Found zip codes with non-digit characters in 'stg.clients'.\")\n",
    "\n",
    "    # Test 3: Verify parsed_state extraction in 'clients'\n",
    "    # Let's see the distribution of the new state column.\n",
    "    print(\"\\n[Value Counts for 'parsed_state' in stg.clients]\")\n",
    "    print(con.execute(\"\"\"\n",
    "        SELECT parsed_state, COUNT(*) AS count \n",
    "        FROM stg.clients \n",
    "        GROUP BY parsed_state \n",
    "        ORDER BY count DESC;\n",
    "    \"\"\").fetchdf())\n",
    "\n",
    "finally:\n",
    "    # Step 2: Ensure the connection is closed after the tests are done\n",
    "    if con:\n",
    "        con.close()\n",
    "        print(\"\\nDatabase connection for verification closed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14b753cb",
   "metadata": {},
   "source": [
    "## Step 4: Create the Final Data Warehouse Layer (`dw_banvic.db`)\n",
    "\n",
    "This is the final step of the data engineering pipeline. The script connects to a new `dw_banvic.db` file, attaches the verified staging database as a source, and builds the final, analysis-ready Star Schema with dimension (`dim_`) and fact (`fct_`) tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7602015c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully connected to '../database/dw_banvic.db'\n",
      "Successfully attached '../database/stg_banvic.db' as 'stg_db'\n",
      "\n",
      "--- Building Data Warehouse Layer (dim and fct tables) ---\n",
      "Table 'dim_dates' created successfully.\n",
      "Table 'dim_agencies' created successfully.\n",
      "Table 'dim_employees' created successfully.\n",
      "Table 'dim_clients' created successfully.\n",
      "Table 'fct_transactions' created successfully.\n",
      "Table 'fct_credit_proposals' created successfully.\n",
      "\n",
      "--- Data Warehouse layer built successfully. ---\n",
      "\n",
      "Database connection closed.\n"
     ]
    }
   ],
   "source": [
    "import duckdb\n",
    "import os\n",
    "\n",
    "# --- Configuration ---\n",
    "# Path to the final Data Warehouse database file\n",
    "dw_db_file = '../database/dw_banvic.db'\n",
    "# Path to the Staging database file (our source)\n",
    "stg_db_file = '../database/stg_banvic.db'\n",
    "\n",
    "# --- SQL Queries for Data Warehouse Layer ---\n",
    "dw_queries = [\n",
    "    {\n",
    "        \"table_name\": \"dim_dates\",\n",
    "        \"sql\": \"\"\"\n",
    "            CREATE OR REPLACE TABLE dim_dates AS\n",
    "            SELECT\n",
    "              d AS full_date,\n",
    "              EXTRACT(YEAR FROM d) AS year,\n",
    "              EXTRACT(QUARTER FROM d) AS quarter,\n",
    "              EXTRACT(MONTH FROM d) AS month,\n",
    "              EXTRACT(WEEK FROM d) AS week_of_year,\n",
    "              EXTRACT(DAY FROM d) AS day,\n",
    "              EXTRACT(DAYOFYEAR FROM d) AS day_of_year,\n",
    "              EXTRACT(DAYOFWEEK FROM d) AS day_of_week,\n",
    "              strftime(d, '%b') AS month_name,\n",
    "              strftime(d, '%a') AS day_of_week_name,\n",
    "\n",
    "            -- This is the syntax for generating the date series\n",
    "            FROM \n",
    "              generate_series(\n",
    "                (SELECT MIN(CAST(transaction_date AS DATE)) FROM stg_db.stg.transactions),\n",
    "                (SELECT MAX(CAST(transaction_date AS DATE)) FROM stg_db.stg.transactions),\n",
    "                interval '1 day'\n",
    "              ) AS t(d);\n",
    "        \"\"\"\n",
    "    },\n",
    "    {\n",
    "        \"table_name\": \"dim_agencies\",\n",
    "        \"sql\": \"CREATE OR REPLACE TABLE dim_agencies AS SELECT * FROM stg_db.stg.agencies;\"\n",
    "    },\n",
    "    {\n",
    "        \"table_name\": \"dim_employees\",\n",
    "        \"sql\": \"\"\"\n",
    "            CREATE OR REPLACE TABLE dim_employees AS\n",
    "            SELECT\n",
    "              e.employee_id,\n",
    "              e.first_name || ' ' || e.last_name AS full_name,\n",
    "              e.email,\n",
    "              e.cpf,\n",
    "              e.birth_date,\n",
    "              ea.agency_id\n",
    "            FROM\n",
    "              stg_db.stg.employee AS e\n",
    "            LEFT JOIN\n",
    "              stg_db.stg.employee_agency AS ea\n",
    "              ON e.employee_id = ea.employee_id;\n",
    "        \"\"\"\n",
    "    },\n",
    "    {\n",
    "        \"table_name\": \"dim_clients\",\n",
    "        \"sql\": \"\"\"\n",
    "            CREATE OR REPLACE TABLE dim_clients AS\n",
    "            SELECT\n",
    "              client_id,\n",
    "              first_name || ' ' || last_name AS full_name,\n",
    "              email,\n",
    "              client_type,\n",
    "              inclusion_date,\n",
    "              cpf_cnpj,\n",
    "              birth_date,\n",
    "              full_address,\n",
    "              zip_code,\n",
    "              parsed_state AS state\n",
    "            FROM\n",
    "              stg_db.stg.clients;\n",
    "        \"\"\"\n",
    "    },\n",
    "    {\n",
    "        \"table_name\": \"fct_transactions\",\n",
    "        \"sql\": \"\"\"\n",
    "            CREATE OR REPLACE TABLE fct_transactions AS\n",
    "            SELECT\n",
    "              t.transaction_id,\n",
    "              b.client_id,\n",
    "              b.agency_id,\n",
    "              b.employee_id,\n",
    "              b.account_id,\n",
    "              CAST(t.transaction_date AS TIMESTAMP) AS transaction_date_id,\n",
    "              t.transaction_name,\n",
    "              t.transaction_amount\n",
    "            FROM\n",
    "              stg_db.stg.transactions AS t\n",
    "            LEFT JOIN\n",
    "              stg_db.stg.bank_accounts AS b\n",
    "              ON t.account_id = b.account_id;\n",
    "        \"\"\"\n",
    "    },\n",
    "    {\n",
    "        \"table_name\": \"fct_credit_proposals\",\n",
    "        \"sql\": \"\"\"\n",
    "            CREATE OR REPLACE TABLE fct_credit_proposals AS\n",
    "            SELECT\n",
    "              cp.proposal_id,\n",
    "              CAST(cp.proposal_date AS DATE) AS proposal_date_id,\n",
    "              cp.client_id,\n",
    "              cp.employee_id,\n",
    "              cp.proposal_status,\n",
    "              cp.monthly_interest_rate,\n",
    "              cp.proposal_amount,\n",
    "              cp.financing_amount,\n",
    "              cp.down_payment_amount,\n",
    "              cp.installment_amount,\n",
    "              cp.number_of_installments,\n",
    "              cp.grace_period\n",
    "            FROM\n",
    "              stg_db.stg.credit_proposal AS cp;\n",
    "        \"\"\"\n",
    "    }\n",
    "]\n",
    "\n",
    "# --- Execution ---\n",
    "con = None\n",
    "try:\n",
    "    # Connect to the DW database file\n",
    "    dw_db_file = '../database/dw_banvic.db'\n",
    "    stg_db_file = '../database/stg_banvic.db'\n",
    "    con = duckdb.connect(dw_db_file)\n",
    "    print(f\"Successfully connected to '{dw_db_file}'\")\n",
    "\n",
    "    # Attach the STAGING database file, giving it an alias 'stg_db'\n",
    "    con.execute(f\"ATTACH '{stg_db_file.replace('\\\\', '/')}' AS stg_db (READ_ONLY);\")\n",
    "    print(f\"Successfully attached '{stg_db_file}' as 'stg_db'\")\n",
    "\n",
    "    # Loop to execute each transformation query\n",
    "    print(\"\\n--- Building Data Warehouse Layer (dim and fct tables) ---\")\n",
    "    for item in dw_queries:\n",
    "        table_name = item[\"table_name\"]\n",
    "        sql_query = item[\"sql\"]\n",
    "        \n",
    "        con.execute(sql_query)\n",
    "        print(f\"Table '{table_name}' created successfully.\")\n",
    "\n",
    "    print(\"\\n--- Data Warehouse layer built successfully. ---\")\n",
    "\n",
    "finally:\n",
    "    # Ensure the connection is closed\n",
    "    if con:\n",
    "        con.close()\n",
    "        print(\"\\nDatabase connection closed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c6ee3fb",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "The data engineering pipeline is now complete. We have a robust, three-layer data architecture ready for the next phase: connecting Power BI to the `dw_banvic.db` file for analysis and visualization."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
